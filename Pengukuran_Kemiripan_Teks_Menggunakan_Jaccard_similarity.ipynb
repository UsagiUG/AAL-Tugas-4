{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnZAZs1Nx31LNCpDSkrewR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UsagiUG/AAL-Tugas-4/blob/main/Pengukuran_Kemiripan_Teks_Menggunakan_Jaccard_similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iFK0BNNkThZ",
        "outputId": "51ea9325-4f75-4908-8417-abd4d979def1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import PyPDF2\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Q1jDhkU-zG-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding files from Google Drive:"
      ],
      "metadata": {
        "id": "OUMf3XLmDIP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path of the file inside Google Drive\n",
        "path1 = \"/content/drive/MyDrive/1-s2.0-S0167404819301117-main.pdf\"\n",
        "path2 = \"/content/drive/MyDrive/1-s2.0-S1389128625003822-main.pdf\"\n",
        "path3 = \"/content/drive/MyDrive/Sebastian Porebski- Evaluation of fuzzy membership functions for linguistic rule-based classifier focused on explainability, interpretability and reliability.pdf\"\n",
        "path4 = \"/content/drive/MyDrive/Interpretable research of fuzzy methods - A literature survey.pdf\""
      ],
      "metadata": {
        "id": "FlCRRJDocvvu"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fYHRDq7lJMC",
        "outputId": "bfa0b172-8740-4fa7-8608-90ef701a0376"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inputting Files:"
      ],
      "metadata": {
        "id": "e6_jMezaCfh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(path):\n",
        "    text = \"\"\n",
        "    # Open PDF in binary mode\n",
        "    with open(path, \"rb\") as f:\n",
        "        reader = PyPDF2.PdfReader(f)\n",
        "        # Extract PDF page-by-page\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "pdf_text_a = extract_text_from_pdf(path1)\n",
        "pdf_text_b = extract_text_from_pdf(path2)\n",
        "pdf_text_c = extract_text_from_pdf(path3)\n",
        "pdf_text_d = extract_text_from_pdf(path4)"
      ],
      "metadata": {
        "id": "kiQ_xuVEeZbb"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX5MKUlMrl5k",
        "outputId": "f3b85da7-bcdb-4caf-bbee-3783c5e302ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Same file:\n",
            "n=1 | Overlap=3110 | Similarity=1.000\n",
            "n=2 | Overlap=10447 | Similarity=1.000\n",
            "n=3 | Overlap=13846 | Similarity=1.000\n",
            "\n",
            "File A & File B citing A\n",
            "n=1 | Overlap=863 | Similarity=0.191\n",
            "n=2 | Overlap=673 | Similarity=0.041\n",
            "n=3 | Overlap=168 | Similarity=0.008\n",
            "\n",
            "File C & File D citing C\n",
            "n=1 | Overlap=1183 | Similarity=0.160\n",
            "n=2 | Overlap=937 | Similarity=0.032\n",
            "n=3 | Overlap=278 | Similarity=0.007\n",
            "\n",
            "Two unrelated files A & C\n",
            "n=1 | Overlap=727 | Similarity=0.139\n",
            "n=2 | Overlap=473 | Similarity=0.026\n",
            "n=3 | Overlap=117 | Similarity=0.005\n",
            "\n",
            "Two unrelated files B & D\n",
            "n=1 | Overlap=1172 | Similarity=0.171\n",
            "n=2 | Overlap=997 | Similarity=0.036\n",
            "n=3 | Overlap=268 | Similarity=0.007\n"
          ]
        }
      ],
      "source": [
        "def get_ngrams(text, n):\n",
        "    # Remove punctuations with regex\n",
        "    clean_text = re.sub(r'[^\\w\\s]','',text)\n",
        "    # Lowercase and split all words\n",
        "    words = clean_text.lower().split()\n",
        "    # Group words into n words per group\n",
        "    return set([tuple(words[i:i+n]) for i in range(len(words)-n+1)])\n",
        "\n",
        "def jaccard_similarity(set_a, set_b):\n",
        "    return len(set_a & set_b) / len(set_a | set_b)\n",
        "\n",
        "def similarity_print(pdf_text_a, pdf_text_b):\n",
        "  for n in [1,2,3]:\n",
        "      ngrams_a = get_ngrams(pdf_text_a, n)\n",
        "      ngrams_b = get_ngrams(pdf_text_b, n)\n",
        "      similarity = jaccard_similarity(ngrams_a, ngrams_b)\n",
        "      print(f\"n={n} | Overlap={len(ngrams_a & ngrams_b)} | Similarity={similarity:.3f}\")\n",
        "\n",
        "print(\"Same file:\")\n",
        "similarity_print(pdf_text_a, pdf_text_a)\n",
        "\n",
        "# Plagiarism-X: 0.02\n",
        "print(\"\\nFile A & File B citing A\")\n",
        "similarity_print(pdf_text_a, pdf_text_b)\n",
        "\n",
        "# Plagiarism-X: 0.02\n",
        "print(\"\\nFile C & File D citing C\")\n",
        "similarity_print(pdf_text_c, pdf_text_d)\n",
        "\n",
        "# Plagiarism-X: 0.01\n",
        "print(\"\\nTwo unrelated files A & C\")\n",
        "similarity_print(pdf_text_a, pdf_text_c)\n",
        "\n",
        "# Plagiarism-X: 0.03\n",
        "print(\"\\nTwo unrelated files B & D\")\n",
        "similarity_print(pdf_text_b, pdf_text_d)\n"
      ]
    }
  ]
}